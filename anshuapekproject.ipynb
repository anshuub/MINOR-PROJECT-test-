{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1eV9BCLPiBrGllj1vQek2LZkOPuMMZPXa","timestamp":1706789205938}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"N5OZ5GBZaUYa","outputId":"63e8062d-1c85-46fc-f420-54416d06f55f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706789429192,"user_tz":-345,"elapsed":193710,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n","!unzip DIV2K_train_HR.zip # This is our dataset link. I will include this command in the description"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-02-01 12:07:14--  http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n","Resolving data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)... 129.132.52.178, 2001:67c:10ec:36c2::178\n","Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip [following]\n","--2024-02-01 12:07:14--  https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n","Connecting to data.vision.ee.ethz.ch (data.vision.ee.ethz.ch)|129.132.52.178|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3530603713 (3.3G) [application/zip]\n","Saving to: ‘DIV2K_train_HR.zip’\n","\n","DIV2K_train_HR.zip  100%[===================>]   3.29G  16.9MB/s    in 2m 37s  \n","\n","2024-02-01 12:09:52 (21.5 MB/s) - ‘DIV2K_train_HR.zip’ saved [3530603713/3530603713]\n","\n","Archive:  DIV2K_train_HR.zip\n","   creating: DIV2K_train_HR/\n","  inflating: DIV2K_train_HR/0103.png  \n","  inflating: DIV2K_train_HR/0413.png  \n","  inflating: DIV2K_train_HR/0031.png  \n","  inflating: DIV2K_train_HR/0660.png  \n","  inflating: DIV2K_train_HR/0126.png  \n","  inflating: DIV2K_train_HR/0793.png  \n","  inflating: DIV2K_train_HR/0764.png  \n","  inflating: DIV2K_train_HR/0550.png  \n","  inflating: DIV2K_train_HR/0437.png  \n","  inflating: DIV2K_train_HR/0374.png  \n","  inflating: DIV2K_train_HR/0755.png  \n","  inflating: DIV2K_train_HR/0614.png  \n","  inflating: DIV2K_train_HR/0646.png  \n","  inflating: DIV2K_train_HR/0371.png  \n","  inflating: DIV2K_train_HR/0312.png  \n","  inflating: DIV2K_train_HR/0108.png  \n","  inflating: DIV2K_train_HR/0556.png  \n","  inflating: DIV2K_train_HR/0794.png  \n","  inflating: DIV2K_train_HR/0722.png  \n","  inflating: DIV2K_train_HR/0780.png  \n","  inflating: DIV2K_train_HR/0555.png  \n","  inflating: DIV2K_train_HR/0439.png  \n","  inflating: DIV2K_train_HR/0396.png  \n","  inflating: DIV2K_train_HR/0666.png  \n","  inflating: DIV2K_train_HR/0254.png  \n","  inflating: DIV2K_train_HR/0344.png  \n","  inflating: DIV2K_train_HR/0062.png  \n","  inflating: DIV2K_train_HR/0657.png  \n","  inflating: DIV2K_train_HR/0117.png  \n","  inflating: DIV2K_train_HR/0395.png  \n","  inflating: DIV2K_train_HR/0015.png  \n","  inflating: DIV2K_train_HR/0335.png  \n","  inflating: DIV2K_train_HR/0578.png  \n","  inflating: DIV2K_train_HR/0142.png  \n","  inflating: DIV2K_train_HR/0719.png  \n","  inflating: DIV2K_train_HR/0101.png  \n","  inflating: DIV2K_train_HR/0579.png  \n","  inflating: DIV2K_train_HR/0504.png  \n","  inflating: DIV2K_train_HR/0576.png  \n","  inflating: DIV2K_train_HR/0590.png  \n","  inflating: DIV2K_train_HR/0158.png  \n","  inflating: DIV2K_train_HR/0384.png  \n","  inflating: DIV2K_train_HR/0795.png  \n","  inflating: DIV2K_train_HR/0668.png  \n","  inflating: DIV2K_train_HR/0144.png  \n","  inflating: DIV2K_train_HR/0642.png  \n","  inflating: DIV2K_train_HR/0427.png  \n","  inflating: DIV2K_train_HR/0593.png  \n","  inflating: DIV2K_train_HR/0080.png  \n","  inflating: DIV2K_train_HR/0050.png  \n","  inflating: DIV2K_train_HR/0617.png  \n","  inflating: DIV2K_train_HR/0608.png  \n","  inflating: DIV2K_train_HR/0118.png  \n","  inflating: DIV2K_train_HR/0082.png  \n","  inflating: DIV2K_train_HR/0788.png  \n","  inflating: DIV2K_train_HR/0042.png  \n","  inflating: DIV2K_train_HR/0333.png  \n","  inflating: DIV2K_train_HR/0346.png  \n","  inflating: DIV2K_train_HR/0705.png  \n","  inflating: DIV2K_train_HR/0195.png  \n","  inflating: DIV2K_train_HR/0671.png  \n","  inflating: DIV2K_train_HR/0213.png  \n","  inflating: DIV2K_train_HR/0692.png  \n","  inflating: DIV2K_train_HR/0253.png  \n","  inflating: DIV2K_train_HR/0191.png  \n","  inflating: DIV2K_train_HR/0628.png  \n","  inflating: DIV2K_train_HR/0354.png  \n","  inflating: DIV2K_train_HR/0003.png  \n","  inflating: DIV2K_train_HR/0393.png  \n","  inflating: DIV2K_train_HR/0336.png  \n","  inflating: DIV2K_train_HR/0674.png  \n","  inflating: DIV2K_train_HR/0586.png  \n","  inflating: DIV2K_train_HR/0074.png  \n","  inflating: DIV2K_train_HR/0116.png  \n","  inflating: DIV2K_train_HR/0270.png  \n","  inflating: DIV2K_train_HR/0376.png  \n","  inflating: DIV2K_train_HR/0650.png  \n","  inflating: DIV2K_train_HR/0462.png  \n","  inflating: DIV2K_train_HR/0046.png  \n","  inflating: DIV2K_train_HR/0545.png  \n","  inflating: DIV2K_train_HR/0347.png  \n","  inflating: DIV2K_train_HR/0187.png  \n","  inflating: DIV2K_train_HR/0713.png  \n","  inflating: DIV2K_train_HR/0558.png  \n","  inflating: DIV2K_train_HR/0319.png  \n","  inflating: DIV2K_train_HR/0073.png  \n","  inflating: DIV2K_train_HR/0033.png  \n","  inflating: DIV2K_train_HR/0207.png  \n","  inflating: DIV2K_train_HR/0290.png  \n","  inflating: DIV2K_train_HR/0194.png  \n","  inflating: DIV2K_train_HR/0246.png  \n","  inflating: DIV2K_train_HR/0034.png  \n","  inflating: DIV2K_train_HR/0621.png  \n","  inflating: DIV2K_train_HR/0768.png  \n","  inflating: DIV2K_train_HR/0366.png  \n","  inflating: DIV2K_train_HR/0490.png  \n","  inflating: DIV2K_train_HR/0471.png  \n","  inflating: DIV2K_train_HR/0475.png  \n","  inflating: DIV2K_train_HR/0152.png  \n","  inflating: DIV2K_train_HR/0636.png  \n","  inflating: DIV2K_train_HR/0338.png  \n","  inflating: DIV2K_train_HR/0358.png  \n","  inflating: DIV2K_train_HR/0523.png  \n","  inflating: DIV2K_train_HR/0456.png  \n","  inflating: DIV2K_train_HR/0470.png  \n","  inflating: DIV2K_train_HR/0522.png  \n","  inflating: DIV2K_train_HR/0426.png  \n","  inflating: DIV2K_train_HR/0587.png  \n","  inflating: DIV2K_train_HR/0465.png  \n","  inflating: DIV2K_train_HR/0236.png  \n","  inflating: DIV2K_train_HR/0192.png  \n","  inflating: DIV2K_train_HR/0458.png  \n","  inflating: DIV2K_train_HR/0438.png  \n","  inflating: DIV2K_train_HR/0176.png  \n","  inflating: DIV2K_train_HR/0016.png  \n","  inflating: DIV2K_train_HR/0392.png  \n","  inflating: DIV2K_train_HR/0054.png  \n","  inflating: DIV2K_train_HR/0063.png  \n","  inflating: DIV2K_train_HR/0537.png  \n","  inflating: DIV2K_train_HR/0271.png  \n","  inflating: DIV2K_train_HR/0409.png  \n","  inflating: DIV2K_train_HR/0328.png  \n","  inflating: DIV2K_train_HR/0582.png  \n","  inflating: DIV2K_train_HR/0532.png  \n","  inflating: DIV2K_train_HR/0706.png  \n","  inflating: DIV2K_train_HR/0153.png  \n","  inflating: DIV2K_train_HR/0401.png  \n","  inflating: DIV2K_train_HR/0110.png  \n","  inflating: DIV2K_train_HR/0316.png  \n","  inflating: DIV2K_train_HR/0069.png  \n","  inflating: DIV2K_train_HR/0209.png  \n","  inflating: DIV2K_train_HR/0351.png  \n","  inflating: DIV2K_train_HR/0433.png  \n","  inflating: DIV2K_train_HR/0534.png  \n","  inflating: DIV2K_train_HR/0525.png  \n","  inflating: DIV2K_train_HR/0353.png  \n","  inflating: DIV2K_train_HR/0018.png  \n","  inflating: DIV2K_train_HR/0592.png  \n","  inflating: DIV2K_train_HR/0041.png  \n","  inflating: DIV2K_train_HR/0398.png  \n","  inflating: DIV2K_train_HR/0355.png  \n","  inflating: DIV2K_train_HR/0492.png  \n","  inflating: DIV2K_train_HR/0258.png  \n","  inflating: DIV2K_train_HR/0051.png  \n","  inflating: DIV2K_train_HR/0339.png  \n","  inflating: DIV2K_train_HR/0156.png  \n","  inflating: DIV2K_train_HR/0174.png  \n","  inflating: DIV2K_train_HR/0526.png  \n","  inflating: DIV2K_train_HR/0168.png  \n","  inflating: DIV2K_train_HR/0515.png  \n","  inflating: DIV2K_train_HR/0289.png  \n","  inflating: DIV2K_train_HR/0700.png  \n","  inflating: DIV2K_train_HR/0711.png  \n","  inflating: DIV2K_train_HR/0317.png  \n","  inflating: DIV2K_train_HR/0310.png  \n","  inflating: DIV2K_train_HR/0075.png  \n","  inflating: DIV2K_train_HR/0533.png  \n","  inflating: DIV2K_train_HR/0345.png  \n","  inflating: DIV2K_train_HR/0238.png  \n","  inflating: DIV2K_train_HR/0493.png  \n","  inflating: DIV2K_train_HR/0019.png  \n","  inflating: DIV2K_train_HR/0559.png  \n","  inflating: DIV2K_train_HR/0268.png  \n","  inflating: DIV2K_train_HR/0746.png  \n","  inflating: DIV2K_train_HR/0648.png  \n","  inflating: DIV2K_train_HR/0112.png  \n","  inflating: DIV2K_train_HR/0639.png  \n","  inflating: DIV2K_train_HR/0216.png  \n","  inflating: DIV2K_train_HR/0170.png  \n","  inflating: DIV2K_train_HR/0408.png  \n","  inflating: DIV2K_train_HR/0461.png  \n","  inflating: DIV2K_train_HR/0774.png  \n","  inflating: DIV2K_train_HR/0308.png  \n","  inflating: DIV2K_train_HR/0368.png  \n","  inflating: DIV2K_train_HR/0341.png  \n","  inflating: DIV2K_train_HR/0535.png  \n","  inflating: DIV2K_train_HR/0585.png  \n","  inflating: DIV2K_train_HR/0004.png  \n","  inflating: DIV2K_train_HR/0496.png  \n","  inflating: DIV2K_train_HR/0662.png  \n","  inflating: DIV2K_train_HR/0173.png  \n","  inflating: DIV2K_train_HR/0200.png  \n","  inflating: DIV2K_train_HR/0752.png  \n","  inflating: DIV2K_train_HR/0106.png  \n","  inflating: DIV2K_train_HR/0520.png  \n","  inflating: DIV2K_train_HR/0519.png  \n","  inflating: DIV2K_train_HR/0157.png  \n","  inflating: DIV2K_train_HR/0552.png  \n","  inflating: DIV2K_train_HR/0735.png  \n","  inflating: DIV2K_train_HR/0362.png  \n","  inflating: DIV2K_train_HR/0410.png  \n","  inflating: DIV2K_train_HR/0286.png  \n","  inflating: DIV2K_train_HR/0627.png  \n","  inflating: DIV2K_train_HR/0557.png  \n","  inflating: DIV2K_train_HR/0266.png  \n","  inflating: DIV2K_train_HR/0252.png  \n","  inflating: DIV2K_train_HR/0206.png  \n","  inflating: DIV2K_train_HR/0330.png  \n","  inflating: DIV2K_train_HR/0088.png  \n","  inflating: DIV2K_train_HR/0728.png  \n","  inflating: DIV2K_train_HR/0641.png  \n","  inflating: DIV2K_train_HR/0350.png  \n","  inflating: DIV2K_train_HR/0083.png  \n","  inflating: DIV2K_train_HR/0682.png  \n","  inflating: DIV2K_train_HR/0549.png  \n","  inflating: DIV2K_train_HR/0564.png  \n","  inflating: DIV2K_train_HR/0476.png  \n","  inflating: DIV2K_train_HR/0760.png  \n","  inflating: DIV2K_train_HR/0629.png  \n","  inflating: DIV2K_train_HR/0630.png  \n","  inflating: DIV2K_train_HR/0032.png  \n","  inflating: DIV2K_train_HR/0581.png  \n","  inflating: DIV2K_train_HR/0056.png  \n","  inflating: DIV2K_train_HR/0040.png  \n","  inflating: DIV2K_train_HR/0169.png  \n","  inflating: DIV2K_train_HR/0400.png  \n","  inflating: DIV2K_train_HR/0172.png  \n","  inflating: DIV2K_train_HR/0182.png  \n","  inflating: DIV2K_train_HR/0269.png  \n","  inflating: DIV2K_train_HR/0612.png  \n","  inflating: DIV2K_train_HR/0649.png  \n","  inflating: DIV2K_train_HR/0311.png  \n","  inflating: DIV2K_train_HR/0723.png  \n","  inflating: DIV2K_train_HR/0166.png  \n","  inflating: DIV2K_train_HR/0155.png  \n","  inflating: DIV2K_train_HR/0072.png  \n","  inflating: DIV2K_train_HR/0149.png  \n","  inflating: DIV2K_train_HR/0425.png  \n","  inflating: DIV2K_train_HR/0715.png  \n","  inflating: DIV2K_train_HR/0670.png  \n","  inflating: DIV2K_train_HR/0460.png  \n","  inflating: DIV2K_train_HR/0748.png  \n","  inflating: DIV2K_train_HR/0147.png  \n","  inflating: DIV2K_train_HR/0602.png  \n","  inflating: DIV2K_train_HR/0610.png  \n","  inflating: DIV2K_train_HR/0479.png  \n","  inflating: DIV2K_train_HR/0603.png  \n","  inflating: DIV2K_train_HR/0043.png  \n","  inflating: DIV2K_train_HR/0190.png  \n","  inflating: DIV2K_train_HR/0503.png  \n","  inflating: DIV2K_train_HR/0055.png  \n","  inflating: DIV2K_train_HR/0337.png  \n","  inflating: DIV2K_train_HR/0453.png  \n","  inflating: DIV2K_train_HR/0219.png  \n","  inflating: DIV2K_train_HR/0548.png  \n","  inflating: DIV2K_train_HR/0661.png  \n","  inflating: DIV2K_train_HR/0718.png  \n","  inflating: DIV2K_train_HR/0489.png  \n","  inflating: DIV2K_train_HR/0775.png  \n","  inflating: DIV2K_train_HR/0323.png  \n","  inflating: DIV2K_train_HR/0664.png  \n","  inflating: DIV2K_train_HR/0002.png  \n","  inflating: DIV2K_train_HR/0127.png  \n","  inflating: DIV2K_train_HR/0322.png  \n","  inflating: DIV2K_train_HR/0640.png  \n","  inflating: DIV2K_train_HR/0473.png  \n","  inflating: DIV2K_train_HR/0730.png  \n","  inflating: DIV2K_train_HR/0008.png  \n","  inflating: DIV2K_train_HR/0486.png  \n","  inflating: DIV2K_train_HR/0597.png  \n","  inflating: DIV2K_train_HR/0064.png  \n","  inflating: DIV2K_train_HR/0068.png  \n","  inflating: DIV2K_train_HR/0510.png  \n","  inflating: DIV2K_train_HR/0594.png  \n","  inflating: DIV2K_train_HR/0685.png  \n","  inflating: DIV2K_train_HR/0497.png  \n","  inflating: DIV2K_train_HR/0637.png  \n","  inflating: DIV2K_train_HR/0332.png  \n","  inflating: DIV2K_train_HR/0208.png  \n","  inflating: DIV2K_train_HR/0241.png  \n","  inflating: DIV2K_train_HR/0201.png  \n","  inflating: DIV2K_train_HR/0044.png  \n","  inflating: DIV2K_train_HR/0141.png  \n","  inflating: DIV2K_train_HR/0381.png  \n","  inflating: DIV2K_train_HR/0412.png  \n","  inflating: DIV2K_train_HR/0035.png  \n","  inflating: DIV2K_train_HR/0049.png  \n","  inflating: DIV2K_train_HR/0181.png  \n","  inflating: DIV2K_train_HR/0340.png  \n","  inflating: DIV2K_train_HR/0272.png  \n","  inflating: DIV2K_train_HR/0279.png  \n","  inflating: DIV2K_train_HR/0307.png  \n","  inflating: DIV2K_train_HR/0733.png  \n","  inflating: DIV2K_train_HR/0250.png  \n","  inflating: DIV2K_train_HR/0739.png  \n","  inflating: DIV2K_train_HR/0654.png  \n","  inflating: DIV2K_train_HR/0343.png  \n","  inflating: DIV2K_train_HR/0422.png  \n","  inflating: DIV2K_train_HR/0297.png  \n","  inflating: DIV2K_train_HR/0360.png  \n","  inflating: DIV2K_train_HR/0099.png  \n","  inflating: DIV2K_train_HR/0541.png  \n","  inflating: DIV2K_train_HR/0616.png  \n","  inflating: DIV2K_train_HR/0352.png  \n","  inflating: DIV2K_train_HR/0092.png  \n","  inflating: DIV2K_train_HR/0528.png  \n","  inflating: DIV2K_train_HR/0483.png  \n","  inflating: DIV2K_train_HR/0631.png  \n","  inflating: DIV2K_train_HR/0134.png  \n","  inflating: DIV2K_train_HR/0625.png  \n","  inflating: DIV2K_train_HR/0530.png  \n","  inflating: DIV2K_train_HR/0454.png  \n","  inflating: DIV2K_train_HR/0624.png  \n","  inflating: DIV2K_train_HR/0501.png  \n","  inflating: DIV2K_train_HR/0038.png  \n","  inflating: DIV2K_train_HR/0365.png  \n","  inflating: DIV2K_train_HR/0789.png  \n","  inflating: DIV2K_train_HR/0010.png  \n","  inflating: DIV2K_train_HR/0543.png  \n","  inflating: DIV2K_train_HR/0635.png  \n","  inflating: DIV2K_train_HR/0418.png  \n","  inflating: DIV2K_train_HR/0159.png  \n","  inflating: DIV2K_train_HR/0689.png  \n","  inflating: DIV2K_train_HR/0429.png  \n","  inflating: DIV2K_train_HR/0276.png  \n","  inflating: DIV2K_train_HR/0255.png  \n","  inflating: DIV2K_train_HR/0293.png  \n","  inflating: DIV2K_train_HR/0327.png  \n","  inflating: DIV2K_train_HR/0488.png  \n","  inflating: DIV2K_train_HR/0244.png  \n","  inflating: DIV2K_train_HR/0721.png  \n","  inflating: DIV2K_train_HR/0652.png  \n","  inflating: DIV2K_train_HR/0779.png  \n","  inflating: DIV2K_train_HR/0687.png  \n","  inflating: DIV2K_train_HR/0326.png  \n","  inflating: DIV2K_train_HR/0161.png  \n","  inflating: DIV2K_train_HR/0498.png  \n","  inflating: DIV2K_train_HR/0264.png  \n","  inflating: DIV2K_train_HR/0136.png  \n","  inflating: DIV2K_train_HR/0006.png  \n","  inflating: DIV2K_train_HR/0741.png  \n","  inflating: DIV2K_train_HR/0421.png  \n","  inflating: DIV2K_train_HR/0229.png  \n","  inflating: DIV2K_train_HR/0373.png  \n","  inflating: DIV2K_train_HR/0703.png  \n","  inflating: DIV2K_train_HR/0516.png  \n","  inflating: DIV2K_train_HR/0234.png  \n","  inflating: DIV2K_train_HR/0405.png  \n","  inflating: DIV2K_train_HR/0763.png  \n","  inflating: DIV2K_train_HR/0619.png  \n","  inflating: DIV2K_train_HR/0138.png  \n","  inflating: DIV2K_train_HR/0513.png  \n","  inflating: DIV2K_train_HR/0432.png  \n","  inflating: DIV2K_train_HR/0177.png  \n","  inflating: DIV2K_train_HR/0017.png  \n","  inflating: DIV2K_train_HR/0736.png  \n","  inflating: DIV2K_train_HR/0459.png  \n","  inflating: DIV2K_train_HR/0505.png  \n","  inflating: DIV2K_train_HR/0397.png  \n","  inflating: DIV2K_train_HR/0591.png  \n","  inflating: DIV2K_train_HR/0196.png  \n","  inflating: DIV2K_train_HR/0724.png  \n","  inflating: DIV2K_train_HR/0740.png  \n","  inflating: DIV2K_train_HR/0223.png  \n","  inflating: DIV2K_train_HR/0442.png  \n","  inflating: DIV2K_train_HR/0165.png  \n","  inflating: DIV2K_train_HR/0302.png  \n","  inflating: DIV2K_train_HR/0386.png  \n","  inflating: DIV2K_train_HR/0601.png  \n","  inflating: DIV2K_train_HR/0370.png  \n","  inflating: DIV2K_train_HR/0647.png  \n","  inflating: DIV2K_train_HR/0267.png  \n","  inflating: DIV2K_train_HR/0380.png  \n","  inflating: DIV2K_train_HR/0441.png  \n","  inflating: DIV2K_train_HR/0037.png  \n","  inflating: DIV2K_train_HR/0678.png  \n","  inflating: DIV2K_train_HR/0304.png  \n","  inflating: DIV2K_train_HR/0494.png  \n","  inflating: DIV2K_train_HR/0028.png  \n","  inflating: DIV2K_train_HR/0613.png  \n","  inflating: DIV2K_train_HR/0257.png  \n","  inflating: DIV2K_train_HR/0100.png  \n","  inflating: DIV2K_train_HR/0097.png  \n","  inflating: DIV2K_train_HR/0604.png  \n","  inflating: DIV2K_train_HR/0023.png  \n","  inflating: DIV2K_train_HR/0782.png  \n","  inflating: DIV2K_train_HR/0446.png  \n","  inflating: DIV2K_train_HR/0378.png  \n","  inflating: DIV2K_train_HR/0411.png  \n","  inflating: DIV2K_train_HR/0320.png  \n","  inflating: DIV2K_train_HR/0390.png  \n","  inflating: DIV2K_train_HR/0148.png  \n","  inflating: DIV2K_train_HR/0577.png  \n","  inflating: DIV2K_train_HR/0684.png  \n","  inflating: DIV2K_train_HR/0595.png  \n","  inflating: DIV2K_train_HR/0765.png  \n","  inflating: DIV2K_train_HR/0203.png  \n","  inflating: DIV2K_train_HR/0288.png  \n","  inflating: DIV2K_train_HR/0058.png  \n","  inflating: DIV2K_train_HR/0790.png  \n","  inflating: DIV2K_train_HR/0605.png  \n","  inflating: DIV2K_train_HR/0248.png  \n","  inflating: DIV2K_train_HR/0467.png  \n","  inflating: DIV2K_train_HR/0210.png  \n","  inflating: DIV2K_train_HR/0517.png  \n","  inflating: DIV2K_train_HR/0707.png  \n","  inflating: DIV2K_train_HR/0566.png  \n","  inflating: DIV2K_train_HR/0224.png  \n","  inflating: DIV2K_train_HR/0114.png  \n","  inflating: DIV2K_train_HR/0761.png  \n","  inflating: DIV2K_train_HR/0468.png  \n","  inflating: DIV2K_train_HR/0716.png  \n","  inflating: DIV2K_train_HR/0420.png  \n","  inflating: DIV2K_train_HR/0669.png  \n","  inflating: DIV2K_train_HR/0375.png  \n","  inflating: DIV2K_train_HR/0140.png  \n","  inflating: DIV2K_train_HR/0792.png  \n","  inflating: DIV2K_train_HR/0240.png  \n","  inflating: DIV2K_train_HR/0546.png  \n","  inflating: DIV2K_train_HR/0235.png  \n","  inflating: DIV2K_train_HR/0077.png  \n","  inflating: DIV2K_train_HR/0260.png  \n","  inflating: DIV2K_train_HR/0212.png  \n","  inflating: DIV2K_train_HR/0584.png  \n","  inflating: DIV2K_train_HR/0633.png  \n","  inflating: DIV2K_train_HR/0060.png  \n","  inflating: DIV2K_train_HR/0164.png  \n","  inflating: DIV2K_train_HR/0622.png  \n","  inflating: DIV2K_train_HR/0105.png  \n","  inflating: DIV2K_train_HR/0005.png  \n","  inflating: DIV2K_train_HR/0679.png  \n","  inflating: DIV2K_train_HR/0089.png  \n","  inflating: DIV2K_train_HR/0466.png  \n","  inflating: DIV2K_train_HR/0645.png  \n","  inflating: DIV2K_train_HR/0301.png  \n","  inflating: DIV2K_train_HR/0499.png  \n","  inflating: DIV2K_train_HR/0020.png  \n","  inflating: DIV2K_train_HR/0070.png  \n","  inflating: DIV2K_train_HR/0404.png  \n","  inflating: DIV2K_train_HR/0749.png  \n","  inflating: DIV2K_train_HR/0770.png  \n","  inflating: DIV2K_train_HR/0772.png  \n","  inflating: DIV2K_train_HR/0450.png  \n","  inflating: DIV2K_train_HR/0120.png  \n","  inflating: DIV2K_train_HR/0653.png  \n","  inflating: DIV2K_train_HR/0563.png  \n","  inflating: DIV2K_train_HR/0171.png  \n","  inflating: DIV2K_train_HR/0784.png  \n","  inflating: DIV2K_train_HR/0688.png  \n","  inflating: DIV2K_train_HR/0045.png  \n","  inflating: DIV2K_train_HR/0066.png  \n","  inflating: DIV2K_train_HR/0583.png  \n","  inflating: DIV2K_train_HR/0632.png  \n","  inflating: DIV2K_train_HR/0512.png  \n","  inflating: DIV2K_train_HR/0767.png  \n","  inflating: DIV2K_train_HR/0623.png  \n","  inflating: DIV2K_train_HR/0406.png  \n","  inflating: DIV2K_train_HR/0419.png  \n","  inflating: DIV2K_train_HR/0273.png  \n","  inflating: DIV2K_train_HR/0198.png  \n","  inflating: DIV2K_train_HR/0750.png  \n","  inflating: DIV2K_train_HR/0220.png  \n","  inflating: DIV2K_train_HR/0482.png  \n","  inflating: DIV2K_train_HR/0407.png  \n","  inflating: DIV2K_train_HR/0704.png  \n","  inflating: DIV2K_train_HR/0547.png  \n","  inflating: DIV2K_train_HR/0589.png  \n","  inflating: DIV2K_train_HR/0012.png  \n","  inflating: DIV2K_train_HR/0150.png  \n","  inflating: DIV2K_train_HR/0481.png  \n","  inflating: DIV2K_train_HR/0357.png  \n","  inflating: DIV2K_train_HR/0677.png  \n","  inflating: DIV2K_train_HR/0315.png  \n","  inflating: DIV2K_train_HR/0394.png  \n","  inflating: DIV2K_train_HR/0160.png  \n","  inflating: DIV2K_train_HR/0667.png  \n","  inflating: DIV2K_train_HR/0568.png  \n","  inflating: DIV2K_train_HR/0435.png  \n","  inflating: DIV2K_train_HR/0606.png  \n","  inflating: DIV2K_train_HR/0464.png  \n","  inflating: DIV2K_train_HR/0364.png  \n","  inflating: DIV2K_train_HR/0245.png  \n","  inflating: DIV2K_train_HR/0508.png  \n","  inflating: DIV2K_train_HR/0356.png  \n","  inflating: DIV2K_train_HR/0135.png  \n","  inflating: DIV2K_train_HR/0146.png  \n","  inflating: DIV2K_train_HR/0574.png  \n","  inflating: DIV2K_train_HR/0698.png  \n","  inflating: DIV2K_train_HR/0222.png  \n","  inflating: DIV2K_train_HR/0261.png  \n","  inflating: DIV2K_train_HR/0444.png  \n","  inflating: DIV2K_train_HR/0078.png  \n","  inflating: DIV2K_train_HR/0123.png  \n","  inflating: DIV2K_train_HR/0797.png  \n","  inflating: DIV2K_train_HR/0274.png  \n","  inflating: DIV2K_train_HR/0225.png  \n","  inflating: DIV2K_train_HR/0180.png  \n","  inflating: DIV2K_train_HR/0325.png  \n","  inflating: DIV2K_train_HR/0372.png  \n","  inflating: DIV2K_train_HR/0029.png  \n","  inflating: DIV2K_train_HR/0318.png  \n","  inflating: DIV2K_train_HR/0452.png  \n","  inflating: DIV2K_train_HR/0115.png  \n","  inflating: DIV2K_train_HR/0423.png  \n","  inflating: DIV2K_train_HR/0615.png  \n","  inflating: DIV2K_train_HR/0672.png  \n","  inflating: DIV2K_train_HR/0231.png  \n","  inflating: DIV2K_train_HR/0731.png  \n","  inflating: DIV2K_train_HR/0389.png  \n","  inflating: DIV2K_train_HR/0680.png  \n","  inflating: DIV2K_train_HR/0329.png  \n","  inflating: DIV2K_train_HR/0663.png  \n","  inflating: DIV2K_train_HR/0659.png  \n","  inflating: DIV2K_train_HR/0292.png  \n","  inflating: DIV2K_train_HR/0284.png  \n","  inflating: DIV2K_train_HR/0133.png  \n","  inflating: DIV2K_train_HR/0727.png  \n","  inflating: DIV2K_train_HR/0445.png  \n","  inflating: DIV2K_train_HR/0139.png  \n","  inflating: DIV2K_train_HR/0298.png  \n","  inflating: DIV2K_train_HR/0282.png  \n","  inflating: DIV2K_train_HR/0778.png  \n","  inflating: DIV2K_train_HR/0565.png  \n","  inflating: DIV2K_train_HR/0485.png  \n","  inflating: DIV2K_train_HR/0495.png  \n","  inflating: DIV2K_train_HR/0215.png  \n","  inflating: DIV2K_train_HR/0694.png  \n","  inflating: DIV2K_train_HR/0321.png  \n","  inflating: DIV2K_train_HR/0094.png  \n","  inflating: DIV2K_train_HR/0598.png  \n","  inflating: DIV2K_train_HR/0430.png  \n","  inflating: DIV2K_train_HR/0021.png  \n","  inflating: DIV2K_train_HR/0036.png  \n","  inflating: DIV2K_train_HR/0188.png  \n","  inflating: DIV2K_train_HR/0334.png  \n","  inflating: DIV2K_train_HR/0759.png  \n","  inflating: DIV2K_train_HR/0217.png  \n","  inflating: DIV2K_train_HR/0562.png  \n","  inflating: DIV2K_train_HR/0124.png  \n","  inflating: DIV2K_train_HR/0690.png  \n","  inflating: DIV2K_train_HR/0385.png  \n","  inflating: DIV2K_train_HR/0695.png  \n","  inflating: DIV2K_train_HR/0708.png  \n","  inflating: DIV2K_train_HR/0745.png  \n","  inflating: DIV2K_train_HR/0007.png  \n","  inflating: DIV2K_train_HR/0226.png  \n","  inflating: DIV2K_train_HR/0256.png  \n","  inflating: DIV2K_train_HR/0673.png  \n","  inflating: DIV2K_train_HR/0451.png  \n","  inflating: DIV2K_train_HR/0143.png  \n","  inflating: DIV2K_train_HR/0403.png  \n","  inflating: DIV2K_train_HR/0125.png  \n","  inflating: DIV2K_train_HR/0132.png  \n","  inflating: DIV2K_train_HR/0644.png  \n","  inflating: DIV2K_train_HR/0796.png  \n","  inflating: DIV2K_train_HR/0076.png  \n","  inflating: DIV2K_train_HR/0211.png  \n","  inflating: DIV2K_train_HR/0676.png  \n","  inflating: DIV2K_train_HR/0121.png  \n","  inflating: DIV2K_train_HR/0415.png  \n","  inflating: DIV2K_train_HR/0536.png  \n","  inflating: DIV2K_train_HR/0620.png  \n","  inflating: DIV2K_train_HR/0331.png  \n","  inflating: DIV2K_train_HR/0277.png  \n","  inflating: DIV2K_train_HR/0611.png  \n","  inflating: DIV2K_train_HR/0262.png  \n","  inflating: DIV2K_train_HR/0305.png  \n","  inflating: DIV2K_train_HR/0521.png  \n","  inflating: DIV2K_train_HR/0221.png  \n","  inflating: DIV2K_train_HR/0699.png  \n","  inflating: DIV2K_train_HR/0743.png  \n","  inflating: DIV2K_train_HR/0742.png  \n","  inflating: DIV2K_train_HR/0111.png  \n","  inflating: DIV2K_train_HR/0480.png  \n","  inflating: DIV2K_train_HR/0720.png  \n","  inflating: DIV2K_train_HR/0402.png  \n","  inflating: DIV2K_train_HR/0561.png  \n","  inflating: DIV2K_train_HR/0729.png  \n","  inflating: DIV2K_train_HR/0296.png  \n","  inflating: DIV2K_train_HR/0379.png  \n","  inflating: DIV2K_train_HR/0014.png  \n","  inflating: DIV2K_train_HR/0714.png  \n","  inflating: DIV2K_train_HR/0754.png  \n","  inflating: DIV2K_train_HR/0634.png  \n","  inflating: DIV2K_train_HR/0725.png  \n","  inflating: DIV2K_train_HR/0309.png  \n","  inflating: DIV2K_train_HR/0197.png  \n","  inflating: DIV2K_train_HR/0039.png  \n","  inflating: DIV2K_train_HR/0696.png  \n","  inflating: DIV2K_train_HR/0758.png  \n","  inflating: DIV2K_train_HR/0599.png  \n","  inflating: DIV2K_train_HR/0228.png  \n","  inflating: DIV2K_train_HR/0712.png  \n","  inflating: DIV2K_train_HR/0539.png  \n","  inflating: DIV2K_train_HR/0781.png  \n","  inflating: DIV2K_train_HR/0009.png  \n","  inflating: DIV2K_train_HR/0145.png  \n","  inflating: DIV2K_train_HR/0527.png  \n","  inflating: DIV2K_train_HR/0263.png  \n","  inflating: DIV2K_train_HR/0122.png  \n","  inflating: DIV2K_train_HR/0506.png  \n","  inflating: DIV2K_train_HR/0363.png  \n","  inflating: DIV2K_train_HR/0249.png  \n","  inflating: DIV2K_train_HR/0104.png  \n","  inflating: DIV2K_train_HR/0800.png  \n","  inflating: DIV2K_train_HR/0214.png  \n","  inflating: DIV2K_train_HR/0658.png  \n","  inflating: DIV2K_train_HR/0399.png  \n","  inflating: DIV2K_train_HR/0572.png  \n","  inflating: DIV2K_train_HR/0204.png  \n","  inflating: DIV2K_train_HR/0651.png  \n","  inflating: DIV2K_train_HR/0061.png  \n","  inflating: DIV2K_train_HR/0026.png  \n","  inflating: DIV2K_train_HR/0300.png  \n","  inflating: DIV2K_train_HR/0162.png  \n","  inflating: DIV2K_train_HR/0478.png  \n","  inflating: DIV2K_train_HR/0022.png  \n","  inflating: DIV2K_train_HR/0079.png  \n","  inflating: DIV2K_train_HR/0285.png  \n","  inflating: DIV2K_train_HR/0511.png  \n","  inflating: DIV2K_train_HR/0025.png  \n","  inflating: DIV2K_train_HR/0428.png  \n","  inflating: DIV2K_train_HR/0436.png  \n","  inflating: DIV2K_train_HR/0324.png  \n","  inflating: DIV2K_train_HR/0447.png  \n","  inflating: DIV2K_train_HR/0457.png  \n","  inflating: DIV2K_train_HR/0424.png  \n","  inflating: DIV2K_train_HR/0675.png  \n","  inflating: DIV2K_train_HR/0469.png  \n","  inflating: DIV2K_train_HR/0090.png  \n","  inflating: DIV2K_train_HR/0179.png  \n","  inflating: DIV2K_train_HR/0771.png  \n","  inflating: DIV2K_train_HR/0431.png  \n","  inflating: DIV2K_train_HR/0726.png  \n","  inflating: DIV2K_train_HR/0609.png  \n","  inflating: DIV2K_train_HR/0184.png  \n","  inflating: DIV2K_train_HR/0747.png  \n","  inflating: DIV2K_train_HR/0154.png  \n","  inflating: DIV2K_train_HR/0391.png  \n","  inflating: DIV2K_train_HR/0573.png  \n","  inflating: DIV2K_train_HR/0071.png  \n","  inflating: DIV2K_train_HR/0798.png  \n","  inflating: DIV2K_train_HR/0693.png  \n","  inflating: DIV2K_train_HR/0280.png  \n","  inflating: DIV2K_train_HR/0414.png  \n","  inflating: DIV2K_train_HR/0119.png  \n","  inflating: DIV2K_train_HR/0757.png  \n","  inflating: DIV2K_train_HR/0762.png  \n","  inflating: DIV2K_train_HR/0734.png  \n","  inflating: DIV2K_train_HR/0001.png  \n","  inflating: DIV2K_train_HR/0265.png  \n","  inflating: DIV2K_train_HR/0643.png  \n","  inflating: DIV2K_train_HR/0567.png  \n","  inflating: DIV2K_train_HR/0130.png  \n","  inflating: DIV2K_train_HR/0580.png  \n","  inflating: DIV2K_train_HR/0463.png  \n","  inflating: DIV2K_train_HR/0218.png  \n","  inflating: DIV2K_train_HR/0769.png  \n","  inflating: DIV2K_train_HR/0507.png  \n","  inflating: DIV2K_train_HR/0013.png  \n","  inflating: DIV2K_train_HR/0233.png  \n","  inflating: DIV2K_train_HR/0087.png  \n","  inflating: DIV2K_train_HR/0093.png  \n","  inflating: DIV2K_train_HR/0709.png  \n","  inflating: DIV2K_train_HR/0027.png  \n","  inflating: DIV2K_train_HR/0570.png  \n","  inflating: DIV2K_train_HR/0342.png  \n","  inflating: DIV2K_train_HR/0011.png  \n","  inflating: DIV2K_train_HR/0287.png  \n","  inflating: DIV2K_train_HR/0524.png  \n","  inflating: DIV2K_train_HR/0791.png  \n","  inflating: DIV2K_train_HR/0701.png  \n","  inflating: DIV2K_train_HR/0783.png  \n","  inflating: DIV2K_train_HR/0349.png  \n","  inflating: DIV2K_train_HR/0766.png  \n","  inflating: DIV2K_train_HR/0232.png  \n","  inflating: DIV2K_train_HR/0314.png  \n","  inflating: DIV2K_train_HR/0303.png  \n","  inflating: DIV2K_train_HR/0697.png  \n","  inflating: DIV2K_train_HR/0514.png  \n","  inflating: DIV2K_train_HR/0377.png  \n","  inflating: DIV2K_train_HR/0085.png  \n","  inflating: DIV2K_train_HR/0113.png  \n","  inflating: DIV2K_train_HR/0540.png  \n","  inflating: DIV2K_train_HR/0383.png  \n","  inflating: DIV2K_train_HR/0243.png  \n","  inflating: DIV2K_train_HR/0086.png  \n","  inflating: DIV2K_train_HR/0091.png  \n","  inflating: DIV2K_train_HR/0151.png  \n","  inflating: DIV2K_train_HR/0502.png  \n","  inflating: DIV2K_train_HR/0294.png  \n","  inflating: DIV2K_train_HR/0281.png  \n","  inflating: DIV2K_train_HR/0656.png  \n","  inflating: DIV2K_train_HR/0500.png  \n","  inflating: DIV2K_train_HR/0237.png  \n","  inflating: DIV2K_train_HR/0387.png  \n","  inflating: DIV2K_train_HR/0178.png  \n","  inflating: DIV2K_train_HR/0518.png  \n","  inflating: DIV2K_train_HR/0239.png  \n","  inflating: DIV2K_train_HR/0131.png  \n","  inflating: DIV2K_train_HR/0655.png  \n","  inflating: DIV2K_train_HR/0417.png  \n","  inflating: DIV2K_train_HR/0776.png  \n","  inflating: DIV2K_train_HR/0560.png  \n","  inflating: DIV2K_train_HR/0737.png  \n","  inflating: DIV2K_train_HR/0048.png  \n","  inflating: DIV2K_train_HR/0128.png  \n","  inflating: DIV2K_train_HR/0052.png  \n","  inflating: DIV2K_train_HR/0137.png  \n","  inflating: DIV2K_train_HR/0686.png  \n","  inflating: DIV2K_train_HR/0053.png  \n","  inflating: DIV2K_train_HR/0665.png  \n","  inflating: DIV2K_train_HR/0691.png  \n","  inflating: DIV2K_train_HR/0167.png  \n","  inflating: DIV2K_train_HR/0313.png  \n","  inflating: DIV2K_train_HR/0531.png  \n","  inflating: DIV2K_train_HR/0569.png  \n","  inflating: DIV2K_train_HR/0553.png  \n","  inflating: DIV2K_train_HR/0047.png  \n","  inflating: DIV2K_train_HR/0096.png  \n","  inflating: DIV2K_train_HR/0756.png  \n","  inflating: DIV2K_train_HR/0440.png  \n","  inflating: DIV2K_train_HR/0199.png  \n","  inflating: DIV2K_train_HR/0283.png  \n","  inflating: DIV2K_train_HR/0247.png  \n","  inflating: DIV2K_train_HR/0024.png  \n","  inflating: DIV2K_train_HR/0193.png  \n","  inflating: DIV2K_train_HR/0084.png  \n","  inflating: DIV2K_train_HR/0102.png  \n","  inflating: DIV2K_train_HR/0551.png  \n","  inflating: DIV2K_train_HR/0575.png  \n","  inflating: DIV2K_train_HR/0477.png  \n","  inflating: DIV2K_train_HR/0098.png  \n","  inflating: DIV2K_train_HR/0554.png  \n","  inflating: DIV2K_train_HR/0189.png  \n","  inflating: DIV2K_train_HR/0717.png  \n","  inflating: DIV2K_train_HR/0732.png  \n","  inflating: DIV2K_train_HR/0702.png  \n","  inflating: DIV2K_train_HR/0183.png  \n","  inflating: DIV2K_train_HR/0448.png  \n","  inflating: DIV2K_train_HR/0455.png  \n","  inflating: DIV2K_train_HR/0367.png  \n","  inflating: DIV2K_train_HR/0251.png  \n","  inflating: DIV2K_train_HR/0744.png  \n","  inflating: DIV2K_train_HR/0785.png  \n","  inflating: DIV2K_train_HR/0067.png  \n","  inflating: DIV2K_train_HR/0163.png  \n","  inflating: DIV2K_train_HR/0751.png  \n","  inflating: DIV2K_train_HR/0299.png  \n","  inflating: DIV2K_train_HR/0129.png  \n","  inflating: DIV2K_train_HR/0291.png  \n","  inflating: DIV2K_train_HR/0607.png  \n","  inflating: DIV2K_train_HR/0242.png  \n","  inflating: DIV2K_train_HR/0107.png  \n","  inflating: DIV2K_train_HR/0175.png  \n","  inflating: DIV2K_train_HR/0753.png  \n","  inflating: DIV2K_train_HR/0278.png  \n","  inflating: DIV2K_train_HR/0369.png  \n","  inflating: DIV2K_train_HR/0571.png  \n","  inflating: DIV2K_train_HR/0202.png  \n","  inflating: DIV2K_train_HR/0030.png  \n","  inflating: DIV2K_train_HR/0799.png  \n","  inflating: DIV2K_train_HR/0474.png  \n","  inflating: DIV2K_train_HR/0491.png  \n","  inflating: DIV2K_train_HR/0638.png  \n","  inflating: DIV2K_train_HR/0600.png  \n","  inflating: DIV2K_train_HR/0596.png  \n","  inflating: DIV2K_train_HR/0059.png  \n","  inflating: DIV2K_train_HR/0186.png  \n","  inflating: DIV2K_train_HR/0509.png  \n","  inflating: DIV2K_train_HR/0529.png  \n","  inflating: DIV2K_train_HR/0787.png  \n","  inflating: DIV2K_train_HR/0382.png  \n","  inflating: DIV2K_train_HR/0777.png  \n","  inflating: DIV2K_train_HR/0109.png  \n","  inflating: DIV2K_train_HR/0227.png  \n","  inflating: DIV2K_train_HR/0388.png  \n","  inflating: DIV2K_train_HR/0618.png  \n","  inflating: DIV2K_train_HR/0681.png  \n","  inflating: DIV2K_train_HR/0205.png  \n","  inflating: DIV2K_train_HR/0472.png  \n","  inflating: DIV2K_train_HR/0306.png  \n","  inflating: DIV2K_train_HR/0361.png  \n","  inflating: DIV2K_train_HR/0738.png  \n","  inflating: DIV2K_train_HR/0230.png  \n","  inflating: DIV2K_train_HR/0081.png  \n","  inflating: DIV2K_train_HR/0095.png  \n","  inflating: DIV2K_train_HR/0449.png  \n","  inflating: DIV2K_train_HR/0626.png  \n","  inflating: DIV2K_train_HR/0065.png  \n","  inflating: DIV2K_train_HR/0443.png  \n","  inflating: DIV2K_train_HR/0275.png  \n","  inflating: DIV2K_train_HR/0542.png  \n","  inflating: DIV2K_train_HR/0484.png  \n","  inflating: DIV2K_train_HR/0359.png  \n","  inflating: DIV2K_train_HR/0773.png  \n","  inflating: DIV2K_train_HR/0434.png  \n","  inflating: DIV2K_train_HR/0544.png  \n","  inflating: DIV2K_train_HR/0416.png  \n","  inflating: DIV2K_train_HR/0295.png  \n","  inflating: DIV2K_train_HR/0538.png  \n","  inflating: DIV2K_train_HR/0259.png  \n","  inflating: DIV2K_train_HR/0348.png  \n","  inflating: DIV2K_train_HR/0588.png  \n","  inflating: DIV2K_train_HR/0710.png  \n","  inflating: DIV2K_train_HR/0786.png  \n","  inflating: DIV2K_train_HR/0185.png  \n","  inflating: DIV2K_train_HR/0057.png  \n","  inflating: DIV2K_train_HR/0487.png  \n","  inflating: DIV2K_train_HR/0683.png  \n"]}]},{"cell_type":"code","metadata":{"id":"tI0KcjC3auG4","executionInfo":{"status":"ok","timestamp":1706805184077,"user_tz":-345,"elapsed":1678,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["# Do set your runtime to GPU. You will need it\n","import torch\n","import math\n","from os import listdir\n","import numpy as np\n","from torch.autograd import Variable"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbIc8Q-Wa0kc","executionInfo":{"status":"ok","timestamp":1706805221801,"user_tz":-345,"elapsed":721,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"JjX6tw0pa61z","executionInfo":{"status":"ok","timestamp":1706805221801,"user_tz":-345,"elapsed":2,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["from torch.utils.data import DataLoader, Dataset"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ARrKwvPdQTp","executionInfo":{"status":"ok","timestamp":1706805221801,"user_tz":-345,"elapsed":1,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["from PIL import Image"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"VgULVo0cvoqw","executionInfo":{"status":"ok","timestamp":1706805222526,"user_tz":-345,"elapsed":3,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["from os.path import join"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgr0F6vldlcC","executionInfo":{"status":"ok","timestamp":1706805222526,"user_tz":-345,"elapsed":2,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}},"outputId":"89210ed3-42d1-49f6-d133-1af79f3b59ec"},"source":["torch.autograd.set_detect_anomaly(True)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7ae2a35263b0>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"Y9gCiSoBdnXC","executionInfo":{"status":"ok","timestamp":1706805224365,"user_tz":-345,"elapsed":3,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["UPSCALE_FACTOR = 4\n","CROP_SIZE = 88"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"1JxvJbk7dqlY","executionInfo":{"status":"ok","timestamp":1706805225847,"user_tz":-345,"elapsed":2,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"N0tpRB2Jdys4","executionInfo":{"status":"ok","timestamp":1706805228146,"user_tz":-345,"elapsed":1,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["# Now, I will load in some code for the dataset and dataloaders.\n","# Link to this notebook will be in the description, so you can get it from there\n","def is_image_file(filename):\n","    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n","\n","\n","def calculate_valid_crop_size(crop_size, upscale_factor):\n","    return crop_size - (crop_size % upscale_factor)\n","\n","\n","def train_hr_transform(crop_size):\n","    return Compose([\n","        RandomCrop(crop_size),\n","        ToTensor(),\n","    ])\n","\n","\n","def train_lr_transform(crop_size, upscale_factor):\n","    return Compose([\n","        ToPILImage(),\n","        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n","        ToTensor()\n","    ])\n","\n","\n","def display_transform():\n","    return Compose([\n","        ToPILImage(),\n","        Resize(400),\n","        CenterCrop(400),\n","        ToTensor()\n","    ])\n","\n","\n","class TrainDatasetFromFolder(Dataset):\n","    def __init__(self, dataset_dir, crop_size, upscale_factor):\n","        super(TrainDatasetFromFolder, self).__init__()\n","        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n","        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n","        self.hr_transform = train_hr_transform(crop_size)\n","        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n","\n","    def __getitem__(self, index):\n","        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n","        lr_image = self.lr_transform(hr_image)\n","        return lr_image, hr_image\n","\n","    def __len__(self):\n","        return len(self.image_filenames)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"tHTaB3fTv11X"},"source":["# That was the dataset code.\n","# Now lets load the train set\n","# Forgot to import join from os.path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"re2-OAGQv-aQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706805230945,"user_tz":-345,"elapsed":434,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}},"outputId":"6e03cd96-232b-461e-f502-9253dc1c0e92"},"source":["train_set = TrainDatasetFromFolder(\"DIV2K_train_HR\", crop_size=CROP_SIZE,\n","                                   upscale_factor=UPSCALE_FACTOR)\n","trainloader = DataLoader(train_set, batch_size=64, num_workers=4, shuffle=True)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","metadata":{"id":"cA8VHoPTwMaz","executionInfo":{"status":"ok","timestamp":1706805232391,"user_tz":-345,"elapsed":1,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["from torch import nn, optim"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQGAwDSGwUnE","executionInfo":{"status":"ok","timestamp":1706805234022,"user_tz":-345,"elapsed":1,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["# Now we will start implementing the model. We will start in this vid, and co,plee\n","# in the next video\n","class ResidualBlock(nn.Module):\n","  def __init__(self, channels):\n","    super(ResidualBlock, self).__init__()\n","    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","    self.bn1 = nn.BatchNorm2d(channels)\n","    self.prelu = nn.PReLU()\n","    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","    self.bn2 = nn.BatchNorm2d(channels)\n","  def forward(self, x):\n","    residual = self.conv1(x)\n","    residual = self.bn1(residual)\n","    residual = self.prelu(residual)\n","    residual = self.conv2(residual)\n","    residual = self.bn2(residual)\n","    return x + residual\n","\n","# We just implemented a pretty standard residual block here"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNpcnPmbw6QQ","executionInfo":{"status":"ok","timestamp":1706805235431,"user_tz":-345,"elapsed":2,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["class UpsampleBlock(nn.Module):\n","  def __init__(self, in_channels, up_scale):\n","    super(UpsampleBlock, self).__init__()\n","    self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2,\n","                          kernel_size=3, padding=1)\n","    self.pixel_shuffle = nn.PixelShuffle(up_scale)\n","    self.prelu = nn.PReLU()\n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.pixel_shuffle(x)\n","    x = self.prelu(x)\n","    return x"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZnfl5c0uzUI","executionInfo":{"status":"ok","timestamp":1706805235930,"user_tz":-345,"elapsed":1,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["class Generator(nn.Module):\n","  def __init__(self, scale_factor):\n","    super(Generator, self).__init__()\n","    upsample_block_num = int(math.log(scale_factor, 2))\n","\n","    self.block1 = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=9, padding=4),\n","        nn.PReLU()\n","    )\n","\n","    self.block2 = ResidualBlock(64)\n","    self.block3 = ResidualBlock(64)\n","    self.block4 = ResidualBlock(64)\n","    self.block5 = ResidualBlock(64)\n","    self.block6 = ResidualBlock(64)\n","    self.block7 = nn.Sequential(\n","        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(64)\n","    )\n","    block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n","    block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n","    self.block8 = nn.Sequential(*block8)\n","  def forward(self, x):\n","    block1 = self.block1(x)\n","    block2 = self.block2(block1)\n","    block3 = self.block3(block2)\n","    block4 = self.block4(block3)\n","    block5 = self.block5(block4)\n","    block6 = self.block6(block5)\n","    block7 = self.block7(block6)\n","    block8 = self.block8(block1 + block7)\n","    return (torch.tanh(block8) + 1) / 2"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ue5xbeyUuzWF","executionInfo":{"status":"ok","timestamp":1706805237775,"user_tz":-345,"elapsed":3,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["class Discriminator(nn.Module):\n","  def __init__(self):\n","    super(Discriminator, self).__init__()\n","    self.net = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.AdaptiveAvgPool2d(1),\n","        nn.Conv2d(512, 1024, kernel_size=1),\n","        nn.LeakyReLU(0.2),\n","        nn.Conv2d(1024, 1, kernel_size=1)\n","    )\n","  def forward(self, x):\n","    batch_size=x.size()[0]\n","    return torch.sigmoid(self.net(x).view(batch_size))"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKD-vlkTxe0F","executionInfo":{"status":"ok","timestamp":1706805240078,"user_tz":-345,"elapsed":2,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["from torchvision.models.vgg import vgg16"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"RamJwy7yxitq","executionInfo":{"status":"ok","timestamp":1706805240079,"user_tz":-345,"elapsed":2,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["# Now we got to make the Generator Loss\n","class TVLoss(nn.Module):\n","  def __init__(self, tv_loss_weight=1):\n","    super(TVLoss, self).__init__()\n","    self.tv_loss_weight=tv_loss_weight\n","  def forward(self, x):\n","    batch_size=x.size()[0]\n","    h_x = x.size()[2]\n","    w_x = x.size()[3]\n","\n","    count_h = self.tensor_size(x[:, :, 1:, :])\n","    count_w = self.tensor_size(x[:, :, :, 1:])\n","\n","    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()\n","    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()\n","    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n","\n","  # Forgot to implement an important method\n","  @staticmethod # Must add this\n","  def tensor_size(t):\n","    return t.size()[1] * t.size()[2] * t.size()[3]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"OiwFaF3tySU_","executionInfo":{"status":"ok","timestamp":1706805241679,"user_tz":-345,"elapsed":1,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["class GeneratorLoss(nn.Module):\n","  def __init__(self):\n","    super(GeneratorLoss, self).__init__()\n","    vgg = vgg16(pretrained=True)\n","    loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n","    for param in loss_network.parameters():\n","      param.requires_grad = False\n","    self.loss_network = loss_network\n","    self.mse_loss = nn.MSELoss()\n","    self.tv_loss = TVLoss()\n","  def forward(self, out_labels, out_images, target_images):\n","    adversial_loss = torch.mean(1 - out_labels)\n","    perception_loss = self.mse_loss(out_images, target_images)\n","    image_loss = self.mse_loss(out_images, target_images)\n","    tv_loss = self.tv_loss(out_images)\n","    return image_loss + 0.001 * adversial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzzSCJjjy7I9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706805243150,"user_tz":-345,"elapsed":2,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}},"outputId":"6c7df917-2918-49d6-fd0e-0b00a468040e"},"source":["device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Standard device selectoin\n","device"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"4oGBnX7PLGJ-","executionInfo":{"status":"ok","timestamp":1706805244549,"user_tz":-345,"elapsed":683,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["netG = Generator(UPSCALE_FACTOR)\n","netD = Discriminator()"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"n39cIDQeLJFO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706805246666,"user_tz":-345,"elapsed":1335,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}},"outputId":"029323a7-b714-4003-9f3b-0a61309e19c1"},"source":["generator_criterion = GeneratorLoss()"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}]},{"cell_type":"code","metadata":{"id":"7ynXcO-8LSgN","executionInfo":{"status":"ok","timestamp":1706805247226,"user_tz":-345,"elapsed":561,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["generator_criterion = generator_criterion.to(device)\n","netG = netG.to(device)\n","netD = netD.to(device)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDlYj1loLiD_","executionInfo":{"status":"ok","timestamp":1706805247881,"user_tz":-345,"elapsed":3,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["optimizerG = optim.Adam(netG.parameters(), lr=0.0002)\n","optimizerD = optim.Adam(netD.parameters(), lr=0.0002)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"doBMeLWOLs_0","executionInfo":{"status":"ok","timestamp":1706805247881,"user_tz":-345,"elapsed":2,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["results = {\n","    \"d_loss\":[],\n","    \"g_loss\":[],\n","    \"d_score\": [],\n","    \"g_score\": []\n","}"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"TVSZCmkvMImY","executionInfo":{"status":"ok","timestamp":1706805249614,"user_tz":-345,"elapsed":2,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["## Now for training code\n","from tqdm import tqdm\n","import os"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"BeTxlp0eML1d","executionInfo":{"status":"ok","timestamp":1706805250683,"user_tz":-345,"elapsed":3,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["N_EPOCHS = 150 # 150 is good enough for our model. gives decent enough results"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"iHadZtxcMO01","outputId":"0980b59f-d47b-4655-8056-1123a2d2a3de","executionInfo":{"status":"error","timestamp":1706805256108,"user_tz":-345,"elapsed":5427,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"source":["for epoch in range(1, N_EPOCHS + 1):\n","  train_bar = tqdm(trainloader)\n","  running_results = {'batch_sizes':0, 'd_loss':0,\n","                     \"g_loss\":0, \"d_score\":0, \"g_score\":0}\n","\n","  netG.train()\n","  netD.train()\n","  for data, target in train_bar:\n","    g_update_first = True\n","    batch_size = data.size(0)\n","    running_results['batch_sizes'] += batch_size\n","\n","    real_img = Variable(target)\n","    real_img = real_img.to(device)\n","    z = Variable(data)\n","    z = z.to(device)\n","\n","    ## Update Discriminator ##\n","    fake_img = netG(z)\n","    netD.zero_grad()\n","    real_out = netD(real_img).mean()\n","    fake_out = netD(fake_img).mean()\n","    d_loss = 1 - real_out + fake_out\n","    d_loss.backward(retain_graph = True)\n","    optimizerD.step()\n","\n","    ## Now update Generator\n","    fake_img = netG(z)\n","    fake_out = netD(fake_img).mean()\n","    netG.zero_grad()\n","    g_loss = generator_criterion(fake_out, fake_img, real_img)\n","    g_loss.backward()\n","\n","    fake_img = netG(z)\n","    fake_out = netD(fake_img).mean()\n","\n","    optimizerG.step()\n","\n","    running_results['g_loss'] += g_loss.item() * batch_size\n","    running_results['d_loss'] += d_loss.item() * batch_size\n","    running_results['d_score'] += real_out.item() * batch_size\n","    running_results['g_score'] += real_out.item() * batch_size\n","\n","    ## Updating the progress bar\n","    train_bar.set_description(desc=\"[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f\" % (\n","        epoch, N_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n","        running_results['g_loss'] / running_results['batch_sizes'],\n","        running_results['d_score'] / running_results['batch_sizes'],\n","        running_results['g_score'] / running_results['batch_sizes']\n","    ))\n","  netG.eval()"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/13 [00:04<?, ?it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-a5e2923093a1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mg_update_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sKivXfVcLHb0","executionInfo":{"status":"ok","timestamp":1706799525239,"user_tz":-345,"elapsed":3690,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}},"outputId":"2c35462d-4806-4609-ee57-7c03b54425e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"KW0VrpXKOAJQ"},"source":["# We will just make sure that this model trains 5 epochs successfuly\n","# This will take around 2 hours to train, please monitor colab\n","# To make sure that it does not time out\n","# There might be few errors, mostly due to typos\n","# The progress bar acts slightly weird\n","# But you see the model is now training\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount Google Drive to save model\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Save model to Google Drive\n","torch.save(netG.state_dict(), '/content/drive/My Drive/generator_weights.pth')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4M1VCwGLlfb","executionInfo":{"status":"ok","timestamp":1706807151441,"user_tz":-345,"elapsed":3547,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}},"outputId":"d942bd6b-8bc4-4750-9111-c5a16bbcd85c"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Load the trained model\n","netG = Generator(UPSCALE_FACTOR)\n","netG.load_state_dict(torch.load('/content/drive/My Drive/generator_weights.pth'))  # Provide the path to your saved model file\n","netG = netG.to(device)  # Move the model to the GPU\n","\n","# Now you can proceed with testing\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import ToTensor\n","from PIL import Image\n","import os\n","\n","# Define Test Dataset Class\n","class TestDatasetFromFolder(Dataset):\n","    def __init__(self, dataset_dir, upscale_factor):\n","        self.image_filenames = [os.path.join(dataset_dir, x) for x in os.listdir(dataset_dir)]\n","        self.upscale_factor = upscale_factor\n","        self.transform = ToTensor()\n","\n","    def __getitem__(self, index):\n","        # Load image\n","        img = Image.open(self.image_filenames[index])\n","        # Apply any preprocessing transforms\n","        img = self.transform(img)\n","        return img\n","\n","    def __len__(self):\n","        return len(self.image_filenames)\n","\n","# Set directory path for test data\n","test_data_dir = \"/content/drive/My Drive/test\"\n","\n","# Set upscale factor\n","upscale_factor = 4  # Adjust as needed\n","\n","# Instantiate Test Dataset\n","test_set = TestDatasetFromFolder(test_data_dir, upscale_factor=upscale_factor)\n","\n","# Set batch size and number of workers for DataLoader\n","batch_size = 1  # Adjust as needed\n","num_workers = 0  # Adjust as needed\n","\n","# Create DataLoader for Testing\n","testloader = DataLoader(test_set, batch_size=batch_size, num_workers=num_workers)\n","\n","# Iterate Over Test DataLoader\n","for data in testloader:\n","    # Perform evaluation using the loaded test data\n","    # Pass each batch of test images through your trained model for evaluation\n","    # Replace the comment below with your evaluation code\n","    # For example, you can print the shape of each batch to ensure it is loaded correctly\n","    print(\"Batch shape:\", data.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqgyLufEQTVw","executionInfo":{"status":"ok","timestamp":1706807154361,"user_tz":-345,"elapsed":698,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}},"outputId":"15d3cd70-2cb6-415f-aa7f-01c8a532d8d5"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Batch shape: torch.Size([1, 3, 1344, 2040])\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","# Iterate over test data and perform evaluation\n","for data_idx, data in enumerate(testloader):\n","    # Perform evaluation using the loaded test data\n","    # Pass each batch of test images through your trained model for evaluation\n","    # Replace the comment below with your evaluation code\n","    # For example:\n","    # predicted_hr_images = netG(data.to(device))\n","\n","    # Convert generated HR images to numpy arrays\n","    generated_hr_images = netG(data.to(device)).detach().cpu().numpy()\n","\n","    # Iterate over batch and visualize results\n","    for i in range(batch_size):\n","        # Convert tensors to numpy arrays for visualization\n","        lr_image = data[i].numpy().transpose((1, 2, 0))  # Convert from CxHxW to HxWxC\n","        hr_image_pred = generated_hr_images[i].transpose((1, 2, 0))  # Convert from CxHxW to HxWxC\n","\n","        # Plot original LR image\n","        plt.subplot(1, 2, 1)\n","        plt.imshow(lr_image)\n","        plt.title('Low-Resolution')\n","\n","        # Plot predicted HR image\n","        plt.subplot(1, 2, 2)\n","        plt.imshow(hr_image_pred)\n","        plt.title('Generated High-Resolution')\n","\n","        plt.show()  # Display the plot\n","\n","        # Save the generated HR image\n","        # save_path = os.path.join('/content/drive/MyDrive/result', f\"generated_hr_image_{data_idx * batch_size + i}.png\")\n","        # plt.imsave(save_path, hr_image_pred)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"R5Z8yxjaTUhw","executionInfo":{"status":"error","timestamp":1706807211426,"user_tz":-345,"elapsed":397,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}},"outputId":"2c9cf298-5b74-46ae-b4f6-99f6b07db032"},"execution_count":46,"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 670.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 11.06 MiB is free. Process 851174 has 14.73 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 9.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-521b7973def6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Convert generated HR images to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mgenerated_hr_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Iterate over batch and visualize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-64900386e432>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mblock8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mblock1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mblock2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mblock3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 670.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 11.06 MiB is free. Process 851174 has 14.73 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 9.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"JI4pE2DwoyLr","executionInfo":{"status":"ok","timestamp":1706807208958,"user_tz":-345,"elapsed":472,"user":{"displayName":"Biraj Subedi","userId":"08184305772609808044"}}},"execution_count":45,"outputs":[]}]}